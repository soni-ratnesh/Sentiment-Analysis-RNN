{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from text files\n",
    "with open('data/reviews.txt', 'r') as f:\n",
    "    reviews = f.read()\n",
    "with open('data/labels.txt', 'r') as f:\n",
    "    labels = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews: bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which\n"
     ]
    }
   ],
   "source": [
    "print(f\"Reviews: {reviews[:500]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "n\n"
     ]
    }
   ],
   "source": [
    "print(f\"Labels: {labels[:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Size of Review dataset : 33678267\n",
      "Size of labels dataset : 225000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Size of Review dataset : {len(reviews)}\n",
    "Size of labels dataset : {len(labels)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the example of the reviews data above. For the processing steps, we'll want to take:\n",
    ">* get rid of periods and extraneous punctuation.\n",
    "* Deal with `\\n`. \n",
    "* Then combined all the reviews back together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "#removing punctuation\n",
    "reviews = reviews.lower()\n",
    "text = ''.join([char for char in reviews if char not in punctuation])\n",
    "\n",
    "# split by new lines and spaces\n",
    "reviews_split = text.split('\\n')\n",
    "text = ' '.join(reviews_split)\n",
    "\n",
    "# create a list of words and labels\n",
    "words = text.split()\n",
    "labels = labels.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bromwell', 'high', 'is', 'a', 'cartoon', 'comedy', 'it', 'ran', 'at', 'the']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_vocab = dict(enumerate(set(words)))\n",
    "vocab_int = {int_vocab[i]: i for i in int_vocab}\n",
    "\n",
    "reviews_ints = []\n",
    "for review in reviews_split:\n",
    "    reviews_ints.append([vocab_int[word] for word in review.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique words: 74072\n",
      "\n",
      "Tokenized review: [49996, 11927, 44533, 12599, 24241, 56281, 17855, 62979, 39587, 44533, 50770, 25044, 26092, 5444, 44533, 53477, 41010, 63441, 1882, 44533, 17704, 63052, 11927, 72843, 37548, 44533, 26503, 35212, 58835, 1882, 67510, 63626, 33794, 49440, 32881, 61707, 30520, 35524, 38247, 10535, 11927, 5007, 44230, 17995, 65462, 5007, 43635, 72843, 35524, 51274, 72306, 5444, 9007, 50214, 55510, 10486, 2268, 5007, 9162, 11335, 16053, 9948, 68940, 48181, 73798, 35524, 9603, 64821, 2368, 67510, 16053, 35524, 47294, 43506, 37387, 17291, 147, 15497, 48149, 10937, 44533, 51872, 56586, 6986, 44533, 20548, 6025, 5007, 44230, 17942, 47684, 70887, 30533, 5279, 5444, 15843, 5710, 58734, 30520, 71885, 41608, 56015, 64220, 71885, 50801, 64936, 18811, 47113, 17099, 52700, 36040, 2368, 71203, 21747]\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "Unique words: {len((vocab_int))}\n",
    "\n",
    "Tokenized review: {reviews_ints[1]}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length reviews: 1\n"
     ]
    }
   ],
   "source": [
    "#reviews with zero length\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "review_lengths = Counter([len(x) for x in reviews_ints])\n",
    "print(f\"Zero-length reviews: {review_lengths[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove zero length review\n",
    "zero_idx = [i for i, review in enumerate(reviews_ints) if len(review) != 0]\n",
    "\n",
    "# remove 0-length reviews and their labels\n",
    "reviews = [reviews_ints[i] for i in zero_idx]\n",
    "labels = np.array([labels[i] for i in zero_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding\n",
    "\n",
    "def pad_feature(token_reviews, seq_length):\n",
    "    features = np.zeros((len(token_reviews),seq_length), dtype=int)\n",
    "    for i, row in enumerate(token_reviews):\n",
    "        features[i,-len(row):]=np.array(row)[:seq_length]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 512\n",
    "features = pad_feature(reviews, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1=positive, 0=negative label conversion\n",
    "labels = np.array([1 if label == 'positive' else 0 for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[46131, 59410, 1882, 44533, 31357, 37548, 5007...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[49996, 11927, 44533, 12599, 24241, 56281, 178...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[55026, 64890, 40864, 57773, 50752, 42051, 213...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[4269, 25044, 57773, 44533, 65703, 30532, 4841...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[20883, 9517, 49689, 30520, 43144, 58060, 1282...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews Labels\n",
       "0  [46131, 59410, 1882, 44533, 31357, 37548, 5007...      1\n",
       "1  [49996, 11927, 44533, 12599, 24241, 56281, 178...      0\n",
       "2  [55026, 64890, 40864, 57773, 50752, 42051, 213...      1\n",
       "3  [4269, 25044, 57773, 44533, 65703, 30532, 4841...      0\n",
       "4  [20883, 9517, 49689, 30520, 43144, 58060, 1282...      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data = pd.DataFrame((reviews,labels), index=[\"Reviews\", \"Labels\"]).T\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data as cleaned.csv\n",
    "data.to_csv('./data/cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/dict/int_vocab.npy\",int_vocab)\n",
    "np.save(\"data/dict/vocab_int.npy\",vocab_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_features(reviews_ints, seq_length):\n",
    "    ''' Return features of review_ints, where each review is padded with 0's \n",
    "        or truncated to the input seq_length.\n",
    "        :prams: reviews_ints: An array of tokenized words\n",
    "        :prams: seq_length: length of resultant reviews\n",
    "        :return: features: reviews_ints with seq_length feature\n",
    "    '''\n",
    "    \n",
    "    # getting the correct rows x cols shape\n",
    "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
    "\n",
    "    # for each review, I grab that review and \n",
    "    for i, row in enumerate(reviews_ints):\n",
    "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 2046\n",
    "\n",
    "#pad reviews\n",
    "features = pad_features(reviews, seq_length=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Shapes:\n",
      "Train set:      (12250, 2046)\n",
      "Validation set: (5250, 2046)\n",
      "Test set:       (7500, 2046) \n"
     ]
    }
   ],
   "source": [
    "#split dataset in train val and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3)\n",
    "\n",
    "print(f\"\"\"Feature Shapes:\n",
    "Train set:      {X_train.shape}\n",
    "Validation set: {X_val.shape}\n",
    "Test set:       {X_test.shape} \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_train,columns=[\"y\"]).join(pd.DataFrame(X_train)).to_csv('data/train.csv', index=False)\n",
    "pd.DataFrame(y_test,columns=[\"y\"]).join(pd.DataFrame(X_test)).to_csv('data/test.csv', index=False)\n",
    "pd.DataFrame(y_val,columns=[\"y\"]).join(pd.DataFrame(X_val)).to_csv('data/val.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
